
static __device__ void *alloc(void *heap, volatile unsigned *free_index, unsigned int heap_size, int nbytes, int *alloc_failed) {
   unsigned char *cheap = (unsigned char *)heap;
   unsigned rounded = nbytes + (8 - (nbytes % 8));
   unsigned offset = atomicAdd((unsigned int *)free_index, rounded);
   if (offset + nbytes > heap_size) { *alloc_failed = 1; return 0x0; }
   else return (void *)(cheap + offset);
}
template<typename T>
inline T *dense_vec_fill(T *alloc, double *vals, unsigned size, unsigned tiling) {
    alloc->values = vals;
    alloc->size = size;
    alloc->tiling = tiling;
    return alloc;
}
template<typename T>
inline T *sparse_vec_fill(T *alloc, double *vals, int *indices, unsigned size, unsigned tiling) {
    alloc->values = vals;
    alloc->indices = indices;
    alloc->size = size;
    alloc->tiling = tiling;
    return alloc;
}
typedef struct scala_Tuple2_I_I_s scala_Tuple2_I_I;
typedef struct org_apache_spark_rdd_cl_tests_Tuple2InputTest__s org_apache_spark_rdd_cl_tests_Tuple2InputTest_;

struct scala_Tuple2_I_I_s{
   int  _1;
   int  _2;
   
};


struct org_apache_spark_rdd_cl_tests_Tuple2InputTest__s{
   
};

typedef struct This_s{
   } This;
static int org_apache_spark_rdd_cl_tests_Tuple2InputTest__anon_1__apply(This *this_ptr, scala_Tuple2_I_I* in){

   return((in->_1 + in->_2));
}
extern "C" __global__ void run(
      int * in0_1, int * in0_2, scala_Tuple2_I_I * in0, 
      int* out, int N, int iter) {
   This thisStruct;
   This* this_ptr=&thisStruct;
   scala_Tuple2_I_I *my_in0 = in0 + (blockIdx.x * blockDim.x + threadIdx.x);
   for (int i = (blockIdx.x * blockDim.x + threadIdx.x); i < N; i += (gridDim.x * blockDim.x)) {
      my_in0->_1 = in0_1[i]; my_in0->_2 = in0_2[i]; 
      out[i] = org_apache_spark_rdd_cl_tests_Tuple2InputTest__anon_1__apply(this_ptr, my_in0);
      
   }
}
